#  K Nearest Neighbor Algorithm - KNN
	K represents the number of the nearest neighbors that we used to classify new data points.
	Choosing the right value of K is called parameter tuning and it’s necessary for better results:
			- K = sqrt (total number of data points).
			- Odd value of K is always selected to avoid confusion between 2 classes.		
		
## Distance Calculation Methods:
	There are various methods for calculating the distance between the points, of which the most commonly known
    methods are –
        1. Euclidean,
        2. Manhattan, 
        3. Minkowski, and
        3. Hamming distance (for categorical)
	
## Somthing to know about KNN:
	1. It is simple to implement.
	2. It is easy to interpret.
	3. Accuracy can be broken down if there are many predictors

Read more about [ k-nearest neighbors algorithm](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm)
